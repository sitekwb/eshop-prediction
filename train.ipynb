{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "with open('records2.json') as file:\n",
    "    sessions = json.load(file)\n",
    "\n",
    "with open('buys2.json') as file:\n",
    "    buys = json.load(file)\n",
    "\n",
    "model_units = 64\n",
    "dense_units = 1\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.DataFrame(sessions)\n",
    "labels = pd.DataFrame(buys)\n",
    "\n",
    "# split to train and test\n",
    "RANDOM_STATE = 76\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
    "                                                    test_size=TEST_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "# end test_train_split\n",
    "\n",
    "# FIT TRANSFORM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-46b2a15751d2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'sigmoid'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'mean_squared_error'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'adam'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/eshop/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001B[0m in \u001B[0;36msummary\u001B[0;34m(self, line_length, positions, print_fn)\u001B[0m\n\u001B[1;32m   1344\u001B[0m     \"\"\"\n\u001B[1;32m   1345\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1346\u001B[0;31m       raise ValueError('This model has not yet been built. '\n\u001B[0m\u001B[1;32m   1347\u001B[0m                        \u001B[0;34m'Build the model first by calling `build()` or calling '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1348\u001B[0m                        \u001B[0;34m'`fit()` with some data, or specify '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = [X_train]\n",
    "y_train = [y_train]\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=1, verbose=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] 0.7484553\n",
      "[0] 0.6010151\n",
      "[0] 0.2997107\n",
      "[0] 0.57123554\n",
      "[0] 0.79648507\n",
      "[0] 0.54842967\n",
      "[0] 0.106711924\n",
      "[0] 0.62032866\n",
      "[0] 0.021594644\n",
      "[0] 0.15486482\n",
      "[0] 0.40980703\n",
      "[0] 0.5079698\n",
      "[0] 0.16251472\n",
      "[0] 0.5963941\n",
      "[0] 0.16269669\n",
      "[0] 0.4579321\n",
      "[0] 0.15979025\n",
      "[0] 0.78711504\n",
      "[0] 0.053117692\n",
      "[0] 0.4806373\n",
      "[0] 0.56947595\n",
      "[0] 0.36378193\n",
      "[0] 0.7784549\n",
      "[0] 0.76632035\n",
      "[0] 0.78327906\n",
      "[0] 0.68455386\n",
      "[0] 0.7784971\n",
      "[0] 0.76640135\n",
      "[0] 0.7001783\n",
      "[0] 0.31185842\n",
      "[0] 0.6367729\n",
      "[0] 0.7372929\n",
      "[0] 0.7937177\n",
      "[0] 0.5751925\n",
      "[0] 0.76239914\n",
      "[0] 0.6621549\n",
      "[0] 0.77297366\n",
      "[0] 0.11012703\n",
      "[0] 0.7594889\n",
      "[0] 0.7236232\n",
      "[0] 0.26197737\n",
      "[0] 0.17839175\n",
      "[0] 0.57132995\n",
      "[0] 0.5650126\n",
      "[0] 0.24478352\n",
      "[0] 0.7346964\n",
      "[0] 0.6679068\n",
      "[0] 0.76180106\n",
      "[0] 0.31757152\n",
      "[0] 0.43053937\n",
      "[0] 0.46719208\n",
      "[0] 0.47120148\n",
      "[0] 0.4525935\n",
      "[0] 0.45643455\n",
      "[0] 0.6702423\n",
      "[0] 0.09236115\n",
      "[0] 0.17100117\n",
      "[0] 0.61186075\n",
      "[0] 0.4945504\n",
      "[0] 0.44225204\n",
      "[0] 0.77026415\n",
      "[0] 0.66566926\n",
      "[0] 0.34779984\n",
      "[0] 0.45464855\n",
      "[0] 0.6849186\n",
      "[0] 0.082231164\n",
      "[0] 0.5296274\n",
      "[0] 0.6600638\n",
      "[0] 0.35173574\n",
      "[0] 0.74251324\n",
      "[0] 0.059085697\n",
      "[0] 0.6820564\n",
      "[0] 0.6613821\n",
      "[0] 0.5550474\n",
      "[0] 0.13394025\n",
      "[0] 0.11351699\n",
      "[0] 0.5201304\n",
      "[0] 0.8637599\n",
      "[0] 0.68654835\n",
      "[0] 0.6989818\n",
      "[0] 0.14846921\n",
      "[0] 0.7181416\n",
      "[0] 0.089863926\n",
      "[0] 0.49092004\n",
      "[0] 0.73947597\n",
      "[0] 0.6103199\n",
      "[0] 0.5707365\n",
      "[0] 0.5841723\n",
      "[0] 0.5121626\n",
      "[0] 0.69487625\n",
      "[0] 0.59270775\n",
      "[0] 0.5621141\n",
      "[0] 0.6069779\n",
      "[0] 0.69253653\n",
      "[0] 0.029667139\n",
      "[0] 0.61587846\n",
      "[0] 0.65292454\n",
      "[0] 0.80899507\n",
      "[0] 0.7022531\n",
      "[0] 0.7221433\n",
      "[0] 0.5907561\n",
      "[0] 0.39984962\n",
      "[0] 0.4180398\n",
      "[0] 0.46990702\n",
      "[0] 0.03153509\n",
      "[0] 0.3313995\n",
      "[0] 0.4484201\n",
      "[0] 0.26446673\n",
      "[0] 0.3389185\n",
      "[0] 0.26834285\n",
      "[0] 0.04000616\n",
      "[0] 0.39712134\n",
      "[0] 0.4854788\n",
      "[0] 0.25551888\n",
      "[0] 0.33379418\n",
      "[0] 0.025206536\n",
      "[0] 0.69828254\n",
      "[0] 0.26471704\n",
      "[0] 0.093845725\n",
      "[0] 0.6859109\n",
      "[0] 0.5729116\n",
      "[0] 0.66639197\n",
      "[0] 0.8143837\n",
      "[0] 0.7828383\n",
      "[0] 0.6808756\n",
      "[0] 0.76968\n",
      "[0] 0.56902814\n",
      "[0] 0.6640215\n",
      "[0] 0.63366014\n",
      "[0] 0.7779361\n",
      "[0] 0.6737195\n",
      "[0] 0.63298976\n",
      "[0] 0.54684\n",
      "[0] 0.524265\n",
      "[0] 0.45542645\n",
      "[0] 0.6333957\n",
      "[0] 0.43230575\n",
      "[0] 0.5458828\n",
      "[0] 0.6588235\n",
      "[0] 0.561033\n",
      "[0] 0.7364902\n",
      "[0] 0.17637423\n",
      "[0] 0.6711543\n",
      "[0] 0.8797475\n",
      "[0] 0.57141674\n",
      "[0] 0.73622745\n",
      "[0] 0.70802414\n",
      "[0] 0.7188627\n",
      "[0] 0.8842873\n",
      "[0] 0.7824929\n",
      "[0] 0.7330977\n",
      "[0] 0.6265538\n",
      "[0] 0.73350835\n",
      "[0] 0.7120662\n",
      "[0] 0.6830697\n",
      "[0] 0.043818265\n",
      "[0] 0.5754837\n",
      "[0] 0.62690204\n",
      "[0] 0.34827095\n",
      "[0] 0.39849398\n",
      "[0] 0.27422446\n",
      "[0] 0.035665035\n",
      "[0] 0.11570093\n",
      "[0] 0.035534263\n",
      "[0] 0.48992264\n",
      "[0] 0.30853015\n",
      "[0] 0.09230971\n",
      "[0] 0.54067564\n",
      "[0] 0.64378726\n",
      "[0] 0.5656213\n",
      "[0] 0.6436411\n",
      "[0] 0.6503264\n",
      "[0] 0.3090264\n",
      "[0] 0.5436711\n",
      "[0] 0.30155092\n",
      "[0] 0.31416488\n",
      "[0] 0.65781564\n",
      "[0] 0.3736512\n",
      "[0] 0.30042535\n",
      "[0] 0.6589768\n",
      "[0] 0.28311044\n",
      "[0] 0.8964803\n",
      "[0] 0.65931976\n",
      "[0] 0.38201946\n",
      "[0] 0.7616143\n",
      "[0] 0.415926\n",
      "[0] 0.587307\n",
      "[0] 0.52939403\n",
      "[0] 0.37370628\n",
      "[0] 0.5296385\n",
      "[0] 0.34350935\n",
      "[0] 0.7797581\n",
      "[0] 0.7078282\n",
      "[0] 0.41658178\n",
      "[0] 0.45948836\n",
      "[0] 0.5215481\n",
      "[0] 0.073262274\n",
      "[0] 0.037600607\n",
      "[0] 0.5844142\n",
      "[0] 0.6814117\n",
      "[0] 0.59170914\n",
      "[0] 0.43187243\n",
      "[0] 0.6775584\n",
      "[0] 0.050937235\n",
      "[0] 0.59439385\n",
      "[0] 0.047563016\n",
      "[0] 0.035349548\n",
      "[0] 0.64345914\n",
      "[0] 0.6157944\n",
      "[0] 0.6369067\n",
      "[0] 0.12719682\n",
      "[0] 0.63161314\n",
      "[0] 0.8057636\n",
      "[0] 0.43058258\n",
      "[0] 0.64375234\n",
      "[0] 0.43118972\n",
      "[0] 0.7238313\n",
      "[0] 0.06233123\n",
      "[0] 0.4826994\n",
      "[0] 0.5\n",
      "[0] 0.4111758\n",
      "[0] 0.435093\n",
      "[0] 0.039705604\n",
      "[0] 0.32972437\n",
      "[0] 0.050349444\n",
      "[0] 0.5491187\n",
      "[0] 0.5222046\n",
      "[0] 0.5253025\n",
      "[0] 0.42848352\n",
      "[0] 0.4210081\n",
      "[0] 0.34414846\n",
      "[0] 0.5952223\n",
      "[0] 0.8059119\n",
      "[0] 0.5805049\n",
      "[0] 0.7344301\n",
      "[0] 0.7332578\n",
      "[0] 0.4327259\n",
      "[0] 0.4732021\n",
      "[0] 0.29418156\n",
      "[0] 0.3114534\n",
      "[0] 0.645479\n",
      "[0] 0.44619372\n",
      "[0] 0.3804116\n",
      "[0] 0.6584605\n",
      "[0] 0.39469022\n",
      "[0] 0.22193164\n",
      "[0] 0.20469531\n",
      "[0] 0.032549143\n",
      "[0] 0.46496773\n",
      "[0] 0.35260278\n",
      "[0] 0.2930119\n",
      "[0] 0.30052656\n",
      "[0] 0.48428938\n",
      "[0] 0.40327924\n",
      "[0] 0.5803925\n",
      "[0] 0.25331712\n",
      "[0] 0.30672312\n",
      "[0] 0.041769475\n",
      "[0] 0.18142256\n",
      "[0] 0.18465307\n",
      "[0] 0.7284134\n",
      "[0] 0.6904107\n",
      "[0] 0.6483487\n",
      "[0] 0.6910461\n",
      "[0] 0.44234428\n",
      "[0] 0.5821905\n",
      "[0] 0.4552224\n",
      "[0] 0.44084513\n",
      "[0] 0.17469576\n",
      "[0] 0.66183627\n",
      "[0] 0.12577882\n",
      "[0] 0.6589611\n",
      "[0] 0.57654065\n",
      "[0] 0.36866155\n",
      "[0] 0.096915394\n",
      "[0] 0.101896554\n",
      "[0] 0.39347148\n",
      "[0] 0.53832334\n",
      "[0] 0.4027666\n",
      "[0] 0.35761756\n",
      "[0] 0.5007983\n",
      "[0] 0.4344953\n",
      "[0] 0.7012917\n",
      "[0] 0.62189007\n",
      "[0] 0.56955343\n",
      "[0] 0.52690864\n",
      "[0] 0.40144974\n",
      "[0] 0.39986962\n",
      "[0] 0.10039702\n",
      "[0] 0.45206055\n",
      "[0] 0.38889652\n",
      "[0] 0.5669196\n",
      "[0] 0.08630195\n",
      "[0] 0.6194899\n",
      "[0] 0.43850988\n",
      "[0] 0.31829244\n",
      "[0] 0.43008864\n",
      "[0] 0.09834263\n",
      "[0] 0.7833867\n",
      "[0] 0.525392\n",
      "[0] 0.42375553\n",
      "[0] 0.40273625\n",
      "[0] 0.40689042\n",
      "[0] 0.4537784\n",
      "[0] 0.3513607\n",
      "[0] 0.4087461\n",
      "[0] 0.68472785\n",
      "[0] 0.44491127\n",
      "[0] 0.114980996\n",
      "[0] 0.71760106\n",
      "[0] 0.028069735\n",
      "[0] 0.49716294\n",
      "[0] 0.13598055\n",
      "[0] 0.1959467\n",
      "[0] 0.84457314\n",
      "[0] 0.13890174\n",
      "[0] 0.13986492\n",
      "[0] 0.85847926\n",
      "[0] 0.80872834\n",
      "[0] 0.74607277\n",
      "[0] 0.8792248\n",
      "[0] 0.67162776\n",
      "[0] 0.5704881\n",
      "[0] 0.82062066\n",
      "[0] 0.6383071\n",
      "[0] 0.8768064\n",
      "[0] 0.54592186\n",
      "[0] 0.5494388\n",
      "[0] 0.70015234\n",
      "[0] 0.13851634\n",
      "[0] 0.5464807\n",
      "[0] 0.5506941\n",
      "[0] 0.57110107\n",
      "[0] 0.51180655\n",
      "[0] 0.70481\n",
      "[0] 0.52553135\n",
      "[0] 0.59362954\n",
      "[0] 0.51816535\n",
      "[0] 0.023105472\n",
      "[0] 0.8272438\n",
      "[0] 0.16422045\n",
      "0.8964803\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#print(y_pred)\n",
    "y_pred = [x[0] for x in y_pred]\n",
    "maxv = 0\n",
    "for a,b in zip(y_test.values.tolist(), y_pred):\n",
    "    if a[0] == 0:\n",
    "        print(a,b)\n",
    "        maxv = max(maxv, b)\n",
    "print(maxv)\n",
    "#loss = keras.losses.mean_squared_error(y_test, y_pred)\n",
    "#print(loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-abe1d7a7",
   "language": "python",
   "display_name": "PyCharm (eshop-prediction)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}